% Chapter 4

\chapter{基于注意力机制的跨分辨率遥感影像计数}
在本节中，将详细介绍一种全新的基于注意力机制的跨分辨率遥感影像计数方法。通过分析CRVC数据集中数据的时间连续性和空间一致性特性，在现有网络基础上，设计了跨分辨率空间注意力和低分辨率下的时空注意力模块，充分结合了图像中的不同尺度，位置信息。
\section{问题分析}
由于直接从极低分辨率的图像中识别出车辆目标具有相当大的难度，本文通过将车辆计数问题转化为图像分割和回归问题来解决这一挑战。这种转换使得处理变得更为可行，是因为不论图像分辨率如何变化，同一类别的车辆数量与车辆实际占用面积之间的线性关系是恒定的。通过数据集中高分辨率图像的计数结果作为同一天同一地点的低分辨率图像的真值是有效的，同时解决了无法直接在低分辨率图像上人工计数得到真值的问题。车辆面积的计算需要基于车辆覆盖率（在图像中的车辆区域百分比）。为了计算车辆覆盖率，我们首先需要通过图像分割技术准确地从低分辨率图像中提取出车辆区域。因此，本文提出的车辆计数大致流程如下：
\begin{enumerate}    
\item 跨分辨率图像处理：选择性地输入高分辨率图像以及与该高分辨率图像同一天的低分辨率图像，同时还包括距离该日期较近和较远的两张低分辨率图像。这些图像被输入到精心设计的分割网络中，该网络专门针对从极低分辨率图像中有效分割车辆区域进行了优化。
\item 车辆覆盖率的计算：通过应用先进的图像处理算法，网络将输出车辆的分割图。这些分割图将用于计算每个车辆的覆盖率，即每辆车在图像中所占的面积与整个图像面积的比例。
\item 车辆面积的转换与回归分析：将得到的车辆覆盖率转换为实际车辆面积，这一步是通过与车辆实际占用面积和数量之间的已知线性关系相结合完成的。我们将使用从高分辨率图像中得到的数据来计算回归模型的系数，这些系数反映了车辆面积与车辆数量之间的关系。然后，这些回归模型系数被应用到低分辨率图像上，以估计出车辆的数量。
\end{enumerate}
通过上述流程处理，即使这些低分辨率图像在视觉上难以分辨车辆细节，我们也能够参照高分辨率图像在极低分辨率图像中有效地进行车辆计数。此方法不仅提高了车辆计数的准确性，还为处理其他低分辨率图像分析任务提供了可能的方法论指导。
\section{网络设计}
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{architecture.png}
    \caption{网络结构}
    \label{fig:architecture}
  \end{figure}
网络设计如图\ref{fig:architecture}所示，网络基于CRVC-Net骨干网络搭建，采用U-Net编码器解码器结构。对于目标低分辨率图像，通过多层卷积网络组成的编码器提取出特征，用作后续解码器输入的一部分。在该编码器结构中，同时保留各层的中间结果，以便后续解码器中对应层使用。

为了利用来自高分辨率图像的先验空间信息和来自其他低分辨率图像的时间连续性约束，引入了两个监督分支跨分辨率空间一致性分支CRSC（crossresolution spatial consistency） 和同分辨率下时间一致性分支IRTC（intraresolution time continuity）。CRSC分支采用和主干编码器相同的架构，提取来自相应高分辨率图像的特征，以使同一天高分辨率图像和低分辨率图像的提取特征尽可能相似。IRTC分支共享主分支的模型及参数，提取来自距离该日期较近和较远的两张低分辨率图像的特征，后续将比较他们和主分支输出的差异。这是因为编码器应具有提取同一分辨率下所有图像的能力，而对于不同分辨率图像来说，像素密度不同导致图像细节不同，采取独立训练的编码器能更好表征不同细节特征，避免造成高分辨率图像细节的丢失，从而影响其指导能力。解码器接受主分支特征作为输入，同时在每一层解码器处，使用对应层的主分支及近处和远处低分辨率图像和高分辨率图像的中间结果作为key，设计了专门的注意力门，综合多渠道输入，进行解码。逐层操作直至生成分割图像。
\section{编码器}
本文设计的网络中，主要通过编码器进行特征提取。网络共接受同样尺寸的4张图像，第一张图像是低分辨率图像\( I^{LR}\)，第二图像为相应日期的高分辨率图像\( I^{HR}\)，第三张和第四张低分辨率图像\( I^{LR}_{close}\)和\( I^{LR}_{far}\)，选取与\( I^{LR}\)日期最接近的图像和与其日期间隔较远的图像。其中\( I^{LR}\)、\(I^{LR}_{close}\)和\( I^{LR}_{far}\)三个低分辨率图像使用同一个编码器，参数共享；\( I^{HR}\)使用结构相同但不共享参数的另一个编码器。这两个编码器用于分别学习同样尺寸的高分辨率和低分辨率图像输入的特征。编码器结构如图\ref{fig:encoder}所示。
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{encoder.png}
    \caption{编码器}
    \label{fig:encoder}
  \end{figure}

编码器被设计为通过逐步减小图像的空间维度（高度和宽度）的同时，增加其特征通道数量，来提取图像的特征，共含有5层。每层结构相同，且保留中间结果用作后续跳跃连接输入。

在每层编码器模块中，首先先通过两个卷积层，每个卷积层都使用3x3的卷积核，激活函数是ReLU，并使用填充，确保输出和输入有相同的空间尺寸，这样可以在不改变空间尺寸的情况下，连续两次增强特征的提取。接着通过一个池化层进行最大池化减半特征图的尺寸，实现下采样。除第一层外，后续连接dropout层以防止过拟合。最后进行批量归一化操作。特征通道的数量在每个编码器模块之后都会增加。在最后一层编码器输出后不进行池化，而是再次通过一个卷积块，为解码器提供特征。


\section{多来源注意力机制}
注意力机制有助于掌握时序信息，同时对于综合不同特征间相关关系有着很强的综合能力。本文中就针对CRVC数据集的特点，设计了自注意力门 SAG（Self Attention Gate）、跨分辨率注意力门 CAG（Crossresolution Attention Gate）和时间序列注意力门 TAG（Timeseires Attention Gate）三种注意力门模块，来充分利用数据集中的时间一致性和空间连续性特征。网络中使用的注意力门结构如图\ref{fig:ag}所示
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{attentionhm.png}
    \caption{注意力门结构}
    \label{fig:ag}
  \end{figure}

其中\(W_{key}\),\(W_x\)和\(\psi\)是三个线性变化的参数矩阵，通过这三个矩阵，注意力的权重就可以通过反向传播进行学习。该门接受两个输入，一个是key，另一个作为query和value。输出的结果是根据key加权得到的新的value，满足下述公式：
\begin{equation}
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V 
\end{equation}

自注意力门，用主分支编码器对应中间层的结果作为key，解码器上一层上采样结果作为query和value进行计算。跨分辨率注意力门，用CRSC分支编码器对应中间层的结果作为key，解码器上一层上采样结果作为query和value进行计算。时间序列注意力门，用两个IRTC编码器对应中间层的结果分别作为key，解码器上一层上采样结果作为query和value进行计算。这样最终得到四个加权后的解码估计，将这些值连接起来作为整体门模块的输出供后续模块使用。

本文设计的网络将主分支、CRSC分支和IRTC分支编码器的对应层的中间结果分别用作注意力机制中的key，而对应的query和value则均来自上一层解码器的输出。这种设计允许模型在每一步解码过程中都重新评估各个编码器分支的重要性，更加动态地融合信息。此方法允许模型根据解码器的当前状态动态调整各个分支的权重，在反向传播中加以修改优化。同时通过考虑来自不同时间和空间信息的多个分支，模型能够更全面的利用数据集中的全部信息。

\section{解码器}
本文设计的网络中，解码器是编码器的对称部分，负责将压缩后的特征图逐步上采样回原始图像的尺寸，并通过注意力门跳跃连接恢复细节信息以生成精确的分割结果。与编码器相同，解码器也包含五个解码器模块。解码器部分的具体细节如图\ref{fig:decoder}所示。
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{decoder.png}
    \caption{解码器}
    \label{fig:decoder}
  \end{figure}

与编码器相同，解码器也包含五个解码器模块。从最深层的特征开始，逐步应用解码器模块，每一步都将特征图的尺寸增大，直到恢复到原始图像的尺寸。将特征图尺寸扩大的关键是

每个解码器模块的输入是前一个块的输出和主分支、CRSC分支和IRTC分支编码器层对应层的输出。首先将前一块输出进行上采样使其和当前层特征尺寸一致。可以使用卷积转置或双线性插值进行上采样。接着将上采样后的输入和经过注意力门的跳跃连接输出连接起来，使用两个3x3卷积层来进行特征提取。最后会通过一个批量归一化和一个卷积块来进一步处理合并后的特征。重复上述操作五次，最终的输出经过一个以SIGMOD函数为激活函数的卷积层后得到最终的输出结果。

最后的结果与初始输入图像的尺寸相同，但通道数为四，分别代表四个汽车类别。
\section{损失函数}
由于CRVC数据集中不同类别间样本数量存在较为显著的差异，本文采用分段多重损失函数来平衡不同类别对模型的影响。
\subsection{轿车计数阶段}
本阶段采用三个损失函数。第一个损失函数为交叉熵损失函数，这个函数常用来衡量概率之间的距离。网络经sigmod输出的分割图也是一种概率分布。用交叉熵衡量其偏差程度有着不错的效果。
\begin{equation}
    \mathcal{L}_{\text {ent }}=-\frac{1}{n} \sum_{i} y_{i} \ln a_{i}
    \label{eq:cross}
\end{equation}

对于高分辨率和低分辨率图像间的空间一致性，它们之间的差异越小，模型对于真实情况的把握就越好。使用如下的损失函数进行约束。
\begin{equation}
    \mathcal{L}_{\text {dif }}=\sum_{i}\left|F_l^{L R}-F^{HR}_{l}\right|^2
\end{equation}

网络接受3个低分辨图像，分别是有高分辨率对应的低分辨率图像，距离这个低分辨率图像时间较近的图像和距离这个低分辨率图像时间较远的图像。由于时间连续性的约束，日期接近的图像间的差异应该小于日期相隔较远的差异。因此这部分损失函数的设计要求相邻日期图像间的差异更小，日期间隔较远的差异较大。下面的公式同时满足上述条件，且符合最小化损失的要求
\begin{equation}
    \mathcal{L}_{\text {ser }}=\sum_{l=1}^{m} \frac{\left|F_{\text {closel }}^{L R}-F^{L R}{ }_{l}\right|}{\left|F_{\text {far } l}^{L R}-F^{L R}_ l\right|}
\end{equation}

这三个损失函数的加权和作为模型训练第一阶段的损失函数。


\subsection{其余类别计数阶段}
为了解决类别不平衡问题，在第一阶段的训练后，采用焦点损失（Focal Loss）作为交叉熵函数的补充。

焦点损失函数（Focal Loss）\cite{2018FocalLossDenseObjectDetection}最初是为解决目标检测中的类别不平衡问题设计的，尤其是在目标识别中背景与前景类别之间的不平衡问题。这种损失函数的设计原理使其同样适用于广泛的多分类问题，特别是在存在明显类别不平衡的情况下。对于包含多种车辆类型的CRVC数据集，各类车辆数量极不平衡，其中包括轿车35844辆、小型货车737辆、大型货车1211辆、起重机60辆。 如果数据集中某些类型的车辆比其他类型少得多，使用焦点损失函数可以带来明显的优势。由于轿车数量显著多于其他几类车辆，采用交叉熵函数（公式~\ref{eq:cross}）时，由于其中的轿车样本占大多数，将显著影响损失函数整体的值，而缩小其他类别对于损失函数的贡献。因此在最终得到的网络中，对于其他几类的分类效果也因此受到影响。


焦点损失函数是交叉熵损失函数的一种改进。焦点损失函数通过重新设计交叉熵损失，可以调节不同数量样本之间的权重，从而使模型对于少量样本的表示能力更强，从而提高模型整体性能。


焦点损失函数的定义如下：
\begin{equation}
    FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)
\end{equation}

其中：\( p_t \) 是模型对当前样本的预测概率，对于正样本 \( p_t = p \)，对于负样本 \( p_t = 1 - p \)。 \( \alpha_t \) 是平衡正负样本权重的系数，通常设置为一个小于 1 的值，用来增加少数类的重要性。\( \gamma \) 是调整易分类样本对损失的影响的聚焦参数，\( \gamma \geq 0 \)。当 \( \gamma = 0 \) 时，Focal Loss 退化为标准的交叉熵损失。\( \gamma \) 的值越大，对易分类样本的惩罚就越大。


通过引入调制因子 \( (1 - p_t)^\gamma \)：当一个样本被错误分类，并且错误程度很大（即 \( p_t \) 很小）时，\( (1 - p_t)^\gamma \) 接近 1，损失不受影响。当一个样本被正确分类，且分类器置信度很大时（即 \( p_t \) 很大）时，\( (1 - p_t)^\gamma \) 接近 0，这使得这类样本对总损失的贡献大大降低，这样可以让模型集中精力学习那些难以分类的样本。


在多分类问题中，焦点损失函数的应用类似于其在二分类中的用法，但需要一些调整来处理多个类别。多分类版本的焦点损失函数通常表示为：

\begin{equation}
    FL(p_t) = - \sum_{c=1}^C \alpha_c (1 - p_{t,c})^\gamma \log(p_{t,c})
\end{equation}


其中：
\( C \) 是类别的总数。\( p_{t,c} \) 是模型对于每个类别 \( c \) 的预测概率。如果样本属于类别 \( c \)，则 \( p_{t,c} \) 是该类别的预测概率；否则为 \( 1 - p_{t,c} \)。\( \alpha_c \) 是针对类别 \( c \) 的平衡系数，用于调节不同类别间的不平衡。\( \gamma \) 是聚焦参数，用来减小易分类样本的损失贡献，增加难分类样本的影响。


通过调节 \( \alpha_c \) 和 \( \gamma \) 参数，焦点损失函数可以帮助模型更好地学习那些样本数量较少的类别。这是通过增加这些类别样本的损失贡献来实现的，从而使模型在训练过程中更加关注它们。通过 \( (1 - p_{t,c})^\gamma \) 这一调节项，焦点损失函数提高了那些模型难以正确分类的样本的损失权重，从而激励模型改进这些区域的预测性能。


对于一个批次中的所有样本，焦点损失函数完整的表达式通常写作：

\begin{equation}
    \mathcal{L}_{\text {FL}} = -\frac{1}{N} \sum_{i=1}^{N}\sum_{c=1}^C \alpha_c (1 - y_{i,c})^\gamma \log(y_{i,c})
\end{equation}


其中：\(N\) 是批次中样本的总数。\( C \) 是类别的总数。\(i\) 是批次中的样本索引。\(y_{i,c}\) 是第 \(i\) 个样本的为类别\( c \)的预测概率，\(\alpha_t\) 是一个调制因子，用于平衡正负样本之间的影响。\(\gamma\) 是一个调整参数，用于减少易分类样本的权重。



最终的损失函数可以将两个阶段各个损失函数加权得到，即
\begin{equation}
    \mathcal{L}=\omega_1\mathcal{L}_{\text {ent }}+\omega_2\mathcal{L}_{\text {dir }}+\omega_3\mathcal{L}_{\text {ser }}
    +\omega_4\mathcal{L}_{\text {FL }}
\end{equation}

其中$\omega_1,\omega_2,\omega_3,\omega_4$为各个损失函数的权重，是设定好的超参数。
